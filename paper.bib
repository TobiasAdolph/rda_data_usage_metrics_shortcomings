% This file was created with JabRef 2.10.
% Encoding: ISO8859_1


@TechReport{cop,
  Title                    = {Code of practice for research data usage metrics release 1},
  Author                   = {Fenner, Martin and Lowenberg, Daniella and Jones, Matt and Needham, Paul and Vieglais, Dave and Abrams, Stephen and Cruse, Patricia and Chodacki, John},
  Institution              = {PeerJ Preprints},
  Year                     = {2018}
}

@Misc{zenodo,
  Title                    = {Usage statistics launched!},

  Author                   = {Alex Ioannidis},
  HowPublished             = {\url{https://blog.zenodo.org/2018/07/18/2018-07-18-usage-statistics}},
  Note                     = {online, accessed 2019-09-02},
  Year                     = {2018}
}

@InProceedings{issi003,
  Title                    = {Research Data Explored II: the Anatomy and Reception of figshare},
  Author                   = {Peter Kraker and Elisabeth Lex and Juan Gorraiz and Christian Gumpenberger and Isabella Peters},
  Booktitle                = {Proceedings of the 20th International Conference on Science and Technology Indicators (STI 2015)},
  Year                     = {2015},

  File                     = {issi003.pdf:issi003.pdf:PDF},
  Keywords                 = {research data, figshare, altmetrics},
  Language                 = {English},
  Owner                    = {di72jiv},
  Timestamp                = {2019.09.18}
}

@Article{issi001,
  Title                    = {Research data explored: an extended analysis of citations and altmetrics},
  Author                   = {Peters, Isabella
and Kraker, Peter
and Lex, Elisabeth
and Gumpenberger, Christian
and Gorraiz, Juan},
  Journal                  = {Scientometrics},
  Year                     = {2016},

  Month                    = {May},
  Number                   = {2},
  Pages                    = {723--744},
  Volume                   = {107},

  Abstract                 = {In this study, we explore the citedness of research data, its distribution over time and its relation to the availability of a digital object identifier (DOI) in the Thomson Reuters database Data Citation Index (DCI). We investigate if cited research data ``impacts'' the (social) web, reflected by altmetrics scores, and if there is any relationship between the number of citations and the sum of altmetrics scores from various social media platforms. Three tools are used to collect altmetrics scores, namely PlumX, ImpactStory, and Altmetric.com, and the corresponding results are compared. We found that out of the three altmetrics tools, PlumX has the best coverage. Our experiments revealed that research data remain mostly uncited (about 85 {\%}), although there has been an increase in citing data sets published since 2008. The percentage of the number of cited research data with a DOI in DCI has decreased in the last years. Only nine repositories are responsible for research data with DOIs and two or more citations. The number of cited research data with altmetrics ``foot-prints'' is even lower (4--9 {\%}) but shows a higher coverage of research data from the last decade. In our study, we also found no correlation between the number of citations and the total number of altmetrics scores. Yet, certain data types (i.e. survey, aggregate data, and sequence data) are more often cited and also receive higher altmetrics scores. Additionally, we performed citation and altmetric analyses of all research data published between 2011 and 2013 in four different disciplines covered by the DCI. In general, these results correspond very well with the ones obtained for research data cited at least twice and also show low numbers in citations and in altmetrics. Finally, we observed that there are disciplinary differences in the availability and extent of altmetrics scores.},
  Day                      = {01},
  Doi                      = {10.1007/s11192-016-1887-4},
  File                     = {issi001.pdf:issi001.pdf:PDF},
  ISSN                     = {1588-2861},
  Owner                    = {di72jiv},
  Timestamp                = {2019.09.18},
  Url                      = {https://doi.org/10.1007/s11192-016-1887-4}
}

@InProceedings{8588646,
  Title                    = {How FAIR Can you Get? Image Retrieval as a Use Case to Calculate FAIR Metrics},
  Author                   = {T. Weber and D. Kranzlm{\"u}ller},
  Booktitle                = {2018 IEEE 14th International Conference on e-Science (e-Science)},
  Year                     = {2018},
  Month                    = {Oct},
  Pages                    = {114-124},

  Doi                      = {10.1109/eScience.2018.00027},
  Keywords                 = {image retrieval;information retrieval;meta data;natural sciences computing;image retrieval;research data services;scientific data management;stewardship;use-case-centric metrics;spatially images;temporally annotated images;image file;data integration workflows;FAIR metrics;Benchmark testing;Metadata;Data integration;Task analysis;Image retrieval;Current measurement;Research Data Management;FAIR Guiding Principles},
  Owner                    = {di72jiv},
  Timestamp                = {2019.08.13}
}

@Misc{dataone,
  Title                    = {DataOne Usage Statistics},
  HowPublished             = {\url{https://releases.dataone.org/online/api-documentation-v2.0.1/design/UsageStatistics.html}},
  Note                     = {online, accessed 2019-09-02}
}

@Misc{dryad,
  Title                    = {Usage Statistics},
  HowPublished             = {\url{http://wiki.datadryad.org/Usage_Statistics}},
  Note                     = {online, accessed 2019-09-02}
}

